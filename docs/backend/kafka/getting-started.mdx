# Getting Started

## Running Kafka

### Using Docker command

Docker command to run Kafka as a single-node cluster for local development:

```sh
docker run --rm --name kafka \
  -p 9092:9092 \
  -e KAFKA_LISTENERS=LOCAL://:9092,CONTROLLER://:9093 \
  -e KAFKA_ADVERTISED_LISTENERS=LOCAL://localhost:9092 \
  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,LOCAL:PLAINTEXT \
  -e KAFKA_NODE_ID=1 \
  -e KAFKA_PROCESS_ROLES=broker,controller \
  -e KAFKA_INTER_BROKER_LISTENER_NAME=LOCAL \
  -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 \
  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
  -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \
  -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \
  -e KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0 \
  -e KAFKA_NUM_PARTITIONS=3 \
  apache/kafka:4.0.0
```

- `KAFKA_LISTENERS`: Defines internal listeners: one for brokers (`LOCAL`) and one for controllers (`CONTROLLER`).
- `KAFKA_ADVERTISED_LISTENERS`: Defines the address that clients can use to connect to the broker (`localhost:9092` in this case).
- `KAFKA_LISTENER_SECURITY_PROTOCOL_MAP`: Maps each listener to the PLAINTEXT protocol (no encryption)
- `KAFKA_NODE_ID=1`: Unique identifier for this Kafka node.
- `KAFKA_PROCESS_ROLES=broker,controller`: Defines this node as both a broker and a controller.
- `KAFKA_INTER_BROKER_LISTENER_NAME=LOCAL`: Defines which listener brokers will use to talk to each other.
- `KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER`: Sets which listener the controllers use.
- `KAFKA_NUM_PARTITIONS=3`: Sets the number of partitions for the default topic.


### Using Docker Compose

Here's a `docker-compose.yml` file to run Kafka and Kafka REST Proxy:

```yml
version: "3.8"
services:
  
  broker-1:
    image: apache/kafka:4.0.0
    hostname: broker-1
    container_name: broker-1
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: BROKER://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker-1:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,BROKER:PLAINTEXT
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    ports:
      - "9092:9092"
    networks:
      - app-net
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1",
        ]
      interval: 5s
      timeout: 10s
      retries: 10
      start_period: 15s

  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:7.4.10
    hostname: rest-proxy
    container_name: rest-proxy
    ports:
      - "8082:8082"
    depends_on:
      - broker-1
    networks:
      - app-net
    environment:
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker-1:9092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"

networks:
  app-net:
    driver: bridge
```

Getting broker list with Kafka REST Proxy:
```sh
curl http://localhost:8082/brokers
```


## Getting Kafka version

Open a shell in the broker container:
```sh
docker exec --workdir /opt/kafka/bin/ -it broker-1 sh
```

Run this command
```sh
./kafka-topics.sh --version
```

## Creating topic

Create a topic:
```sh
./kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test-topic --partitions 2 --replication-factor 1
```
- `--partitions 2`: split topic to 2 partitions


## Sending events

```sh
./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test-topic
```

After entering some text, press `Ctrl+C` to exit.

To distribute messages across partitions, you've to use keyed message, and Kafka will use the hash of the key to determine the partition:

```sh
./kafka-console-producer.sh \
  --bootstrap-server localhost:9092 \
  --topic my-new-topic \
  --property "parse.key=true" \
  --property "key.separator=:"
```

Then, enter messages like:
```
key1:Hello from partition X
key2:Another message
```


## Consuming events

```sh
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --group group-1 --from-beginning
```
- `--group group-1`: specify the consumer group to `group-1`

> [!NOTE]
> Consumers in the same group don't process the same message