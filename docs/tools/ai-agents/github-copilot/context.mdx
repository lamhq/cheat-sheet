# Context Setup

How to provide targeted project information to AI agents, enabling them to generate higher-quality code and make better architectural decisions aligned with your project's conventions and goals.

## Workflow

Workflow for context preparation:
1. **Curate project-wide context**: use **custom instructions** to include relevant documentation (for example, architecture, design, contributor guidelines) as context to all agent interactions.
2. **Generate implementation plan**: create a planning persona by using a **custom agent** and a prompt to generate a detailed feature implementation plan.
3. **Generate implementation code**: use **custom instructions** to generate code based on the implementation plan that adheres to your coding guidelines.

![](https://code.visualstudio.com/assets/docs/copilot/context-engineering-guide/context-engineering-workflow.png)


## Step 1: Curate project-wide context

1. Collect key project information (product vision, architecture, guidelines, etc).
2. Create a `.github/copilot-instructions.md` instructions file that provides context and guidelines for all chat interactions. You can reference documentation files (using Markdown links)

**Tips**:

- Start small, keeping the initial project-wide context concise and focused on the most critical information
- Only add new rules to address errors or incorrect behavior the agent makes repeatedly (using the wrong shell command, ignoring certain files, etc)
- Avoid including context that is too specific or irrelevant

```md title=".github/copilot-instructions.md"
# [Project Name] Guidelines

* [Product Vision and Goals](!../PRODUCT.md): Understand the high-level vision and objectives of the product to ensure alignment with business goals.
* [System Architecture and Design Principles](!../ARCHITECTURE.md): Overall system architecture, design patterns, and design principles that guide the development process.
* [Contributing Guidelines](!../CONTRIBUTING.md): Overview of the project's contributing guidelines and collaboration practices.

Suggest to update these documents if you find any incomplete or conflicting information during your work.
```

## Step 2: Create implementation plan

Use AI to create a detailed implementation plan for new features or bug fixes.

1. Create a planning document template `plan-template.md` that defines the structure and sections of a implementation plan document:
2. Create a custom agent (`.github/agents/plan.agent.md`) for planning to provide a dedicated persona with specific guidelines (this might require multiple rounds of refinement):
3. Create a prompt file `.github/prompts/plan.prompt.md` that invokes plan agent and instructs the agent to create an implementation plan from a provided feature request.

```md title="plan-template.md"
---
title: [Short descriptive title of the feature]
version: [optional version number]
date_created: [YYYY-MM-DD]
last_updated: [YYYY-MM-DD]
---
# Implementation Plan: <feature>
[Brief description of the requirements and goals of the feature]

## Architecture and design
Describe the high-level architecture and design considerations.

## Tasks
Break down the implementation into smaller, manageable tasks using a Markdown checklist format.

## Open questions
Outline 1-3 open questions or uncertainties that need to be clarified.
```

```md title=".github/agents/plan.agent.md"
---
description: 'Architect and planner to create detailed implementation plans.'
tools: ['fetch', 'githubRepo', 'problems', 'usages', 'search', 'todos', 'runSubagent', 'github/github-mcp-server/get_issue', 'github/github-mcp-server/get_issue_comments', 'github/github-mcp-server/list_issues']
handoffs:
- label: Start Implementation
    agent: tdd
    prompt: Now implement the plan outlined above using TDD principles.
    send: true
---
# Planning Agent

You are an architect focused on creating detailed and comprehensive implementation plans for new features and bug fixes. Your goal is to break down complex requirements into clear, actionable tasks that can be easily understood and executed by developers.

## Workflow

1. Analyze and understand: Gather context from the codebase and any provided documentation to fully understand the requirements and constraints. Run #tool:runSubagent tool, instructing the agent to work autonomously without pausing for user feedback.
2. Structure the plan: Use the provided [implementation plan template](!plan-template.md) to structure the plan.
3. Pause for review: Based on user feedback or questions, iterate and refine the plan as needed.
```

```md title=".github/prompts/plan.prompt.md"
---
agent: plan
description: Create a detailed implementation plan.
---
Briefly analyze my feature request, then ask me 3 questions to clarify the requirements. Only then start the planning workflow.
```


## Step 3: Generate implementation code

1. For smaller tasks, prompt the agent to generate code based on the implementation plan.
2. For larger or complex features, use a **Plan Agent** to generate & save the implementation plan to a file, reference it in a new chat session to keep context clean.
3. For a more customized workflow, create a custom agent `.github/agents/implement.agent.md` specialized in implementing code based on a plan:

```md title=".github/agents/implement.agent.md"
---
description: 'Execute a detailed implementation plan as a test-driven developer.'
---
# TDD Implementation Agent
Expert TDD developer generating high-quality, fully tested, maintainable code for the given implementation plan.

## Test-driven development
1. Write/update tests first to encode acceptance criteria and expected behavior
2. Implement minimal code to satisfy test requirements
3. Run targeted tests immediately after each change
4. Run full test suite to catch regressions before moving to next task
5. Refactor while keeping all tests green

## Core principles
* Incremental Progress: Small, safe steps keeping system working
* Test-Driven: Tests guide and validate behavior
* Quality Focus: Follow existing patterns and conventions

## Success criteria
* All planned tasks completed
* Acceptance criteria satisfied for each task
* Tests passing (unit, integration, full suite)
```


## Best practices

### Context management principles

**Start small and iterate**: Begin with minimal project context rather than dumping excessive information.

**Keep context fresh**: Regularly audit and update your project documentation (using the agent) as the codebase evolves.

**Maintain context isolation**: Keep different types of work (planning, coding, testing, debugging) in separate chat sessions to prevent context mixing and confusion.

**Version your context**: Use git to track changes to your context engineering setup, allowing you to revert problematic changes and understand what works best.

**Create multi-level context**: Creating context hierarchies with project-wide, module-specific, and feature-specific context layers using instructions files.

**For multi-project**: Create reusable templates and patterns that can be adopted across different codebases and domains.

### Documentation strategies

**Create living documents**: Refine your custom instructions, custom agents, and templates based on observed AI mistakes or shortcomings.

**Document convention & patterns**: Establish and document coding conventions, naming patterns, and architectural decisions to help AI generate consistent code.

**Reference external knowledge**: Link to relevant external documentation, APIs, or standards that the AI should consider when generating code.


### Workflow optimization

**Separate concerns**: Use different agents for different activities (planning, implementation, review) to maintain focused, relevant context.

**Handoffs between agents**: Use handoffs to transit works between agents for implementing end-to-end development workflows.

**Use incremental complexity**: Build features incrementally, validating each step before adding complexity.


### Anti-patterns to avoid

Avoid providing excessive, unfocused information that doesn't directly help with decision-making.

Don't assume AI correctly understands your context. Always test understanding before proceeding with complex implementations.

Be flexible in your approach. Different team members or project phases may need different context configurations.


### Measuring success

A successful context engineering setup should result in:

- **Reduced prompts**: Less need to correct or refine AI responses
- **Consistent code quality**: Generated code follows established patterns and conventions
- **Faster implementation**: Less time spent providing context and requirements
- **Better architectural decisions**: AI suggests solutions that align with project goals and constraints
